---
title: "ELM Model and statstics analysis"
author: "Hao Yuan"
date: '2023-03-29'
output: html_document
---

# ELM modeling& statstics analysis by R

```{r}
#for data processing 
library(tidyverse)

#for EDA
library(GGally)
library(ggplot2)

#for ELM&regression
library(elmNNRcpp)
library(KernelKnn)
library(corrplot)
library(glmnet)
library(caret)
library(ELMR)
```

## Data Processing&EDA

```{r}
#load the data
temp <- read.csv("temperature_nsw.csv")
demd<-read.csv("totaldemand_nsw.csv")

#Only preserve useful data
temp<-temp[,-1]
demd<-demd[,1:2]

#merge two dataframe into one 
total<-merge(temp,demd,by="DATETIME")
total<-total[,2:3]
ggpairs(total)
total=as.matrix(total)
```

## Key findings from EDA

路 Normal distribution for temperature and total demand\
路 A low correlation coefficient between temperature and total demand\
路 Forecast of demand is not accuracy when later night and early morning.\
路 The sum of delta of forecast and real demand is lower when extreme weather.\

## ELM modeling

```{r}
set.seed(1000)
traindata<-total[sample(1:nrow(total),round(0.8*nrow(total))),]
testdata<-total[(nrow(traindata)+1):nrow(total),]
train_x<-as.matrix(traindata[,-ncol(traindata)])
train_y<-as.matrix(traindata[,ncol(traindata),drop=FALSE])
test_x<-as.matrix(testdata[,-ncol(testdata)])
test_y<-as.matrix(testdata[,ncol(testdata),drop=FALSE])


model<-elm_train(train_x,train_y,nhid=50,actfun='purelin',init_weights='normal_gaussian')
predict_y = elm_predict(model,test_x)
data.frame(rmse=sqrt(mean((predict_y-test_y)^2)),mape=mean(abs(predict_y-test_y)/test_y))


```

```{r}
plot(predict_y,type='l',xlab = 'samples',ylab = 'forecastdemand',main = 'ELM regression of demand')
lines(test_y,type = 'l',col="red")
```

According to the basic ELM(Extreme Learning Machine)model, we got the first plot and rmse of this model,2732. To make the model more efficient, we are going to make some more analysis.

### Statstics Analysis

```{r}
#polynomial regression
fit1<-lm(total[,2]~poly(total[,1],3))
summary(fit1)
```

From polynomial regression, we conclude that this model should include more features.

```{r}
#ridge regression
ridge=glmnet(x=train,y=train_y,family = 'gaussian',alpha = 0)
plot(ridge,xvar = 'lambda')
```

```{r}
set.seed(123)
cv.ridge=cv.glmnet(x=train,y=train_y,family='gaussian',alpha=0)
plot(cv.ridge)
```

```{r}
pre_ridge=predict(cv.ridge,newx=test)
rmse_ridge=sqrt(mean((pre_ridge-test_y)^2))
rmse_ridge
```

From the ridge regression,We could see that we have the least MSE when log(lambda) between 2 and 3 and the RMSE of ridge regression is 1218, which means it has a better performance than ELM model.

```{r}
#lasso regression
lasso=glmnet(x=train,y=train_y,family = 'gaussian',alpha = 1)
plot(lasso,xvar = 'lambda')
```

```{r}
set.seed(123)
cv.lasso=cv.glmnet(x=train,y=train_y,family='gaussian',alpha=1)
plot(cv.lasso)
```

When it comes to lasso regression, log(lamda) between 0 and 2 can make MSE least.

```{r}
pre_lasso=predict(cv.lasso,newx=test)
rmse_lasso=sqrt(mean((pre_lasso-test_y)^2))
rmse_lasso
```

Obviously, lasso regression perform better than ridge. By the front analysis, we should add some features to ELM model to get a lower RMSE.

```{r}
#ELM model with more features
train<-cbind(train_x,train_x^2,train_x^3)
test<-cbind(test_x,test_x^2,test_x^3)
model<-elm_train(train,train_y,nhid=50,actfun='purelin',init_weights='normal_gaussian')
predict_y = elm_predict(model,test)
data.frame(rmse=sqrt(mean((predict_y-test_y)^2)),mape=mean(abs(predict_y-test_y)/test_y))
```

```{r}
plot(predict_y,type='l',xlab = 'samples',ylab = 'forecastdemand',main = 'ELM regression of demand')
lines(test_y,type = 'l',col="red")
```

After adding two power features, it seems like we get a better model but there is a special situation happens, a kind of overfitting. To avoid it, we usually use these steps:dropout,regularization,batch normalization and so on, for this model, we are going to use cross-validation to check if overfitting happens.

```{r}
#ELM with 10-folds(cross validation)
X<-cbind(total[,1],total[,1]^2,total[,1]^3)
Y<-as.matrix(total[,2])
data<-cbind(X,total[,2])

train.index <- sample(1:nrow(data), 0.8*nrow(data))
train.data <- data[train.index, ]
test.data <- data[-train.index, ]


elm_model <- function(X_train, Y_train, X_test) {
  elm <- elm_train(X_train, Y_train,nhid=50,actfun='purelin',init_weights='normal_gaussian')  
  Y_pred <- elm_predict(elm,X_test)  
  return(Y_pred)
}
k_fold_cv <- function(data, k) {
  mse <- rep(0, k)  
  
  for(i in 1:k) {
    # split data
    folds <- cut(seq(1, nrow(data)), breaks = k, labels = FALSE)
    validation.index <- which(folds == i, arr.ind = TRUE)
    validation.data <- data[validation.index, ]
    train.data <- data[-validation.index, ]
    
  
    Y_pred <- elm_model(train.data[, -ncol(train.data)], as.matrix(train.data[, ncol(train.data)]), 
                        validation.data[, -ncol(validation.data)])
    
    mse[i] <- sum((Y_pred - validation.data[, ncol(validation.data)])^2) / length(Y_pred)
  }
  
  cv_error <- mean(mse)  
  
  return(cv_error)
}
cv_test <- k_fold_cv(train.data, 10)
print(cv_error)
```

```{r}
cv_rmse <- sqrt(cv_error)
print(cv_rmse)
```

The RMSE of 10-folds cross validation reflects there is no overfitting on that ELM model.
